{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_hub\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    data_dir=\"data/artbench-10\",\n",
    "    img_size=(224, 224),\n",
    "    batch_size=128,\n",
    "    val_split=0.2,\n",
    "    seed=42,\n",
    "    epochs=200,\n",
    "    lr_warmup=5e-4,\n",
    "    lr_finetune=3e-5,\n",
    "    preset=\"resnet_v2_50_imagenet\",\n",
    "    results_dir=\"results\",\n",
    "    warmup_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm_id = os.environ.get(\"SLURM_JOB_ID\", \"\")\n",
    "tag = f\"_{slurm_id}\" if slurm_id else \"\"\n",
    "\n",
    "os.makedirs(args.results_dir, exist_ok=True)\n",
    "\n",
    "# Seeds\n",
    "tf.keras.utils.set_random_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_get_preset_preprocessor(preset: str):\n",
    "    try:\n",
    "        from keras_hub import layers as kh_layers\n",
    "        if hasattr(kh_layers, \"PresetPreprocessor\"):\n",
    "            return kh_layers.PresetPreprocessor.from_preset(preset)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if hasattr(keras_hub.models.ImageClassifier, \"preprocessor_from_preset\"):\n",
    "            return keras_hub.models.ImageClassifier.preprocessor_from_preset(preset)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "preproc_layer = try_get_preset_preprocessor(args.preset)\n",
    "print(\"Using preset preprocessor:\", bool(preproc_layer is not None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(data_dir, img_size, batch_size, val_split, seed, preproc_layer=None):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, \"train\"),\n",
    "        validation_split=val_split,\n",
    "        subset=\"training\",\n",
    "        seed=seed,\n",
    "        image_size=tuple(img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"int\",\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, \"train\"),\n",
    "        validation_split=val_split,\n",
    "        subset=\"validation\",\n",
    "        seed=seed,\n",
    "        image_size=tuple(img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"int\",\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, \"test\"),\n",
    "        image_size=tuple(img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"int\",\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    if preproc_layer is not None:\n",
    "        def _map(x, y):\n",
    "            x = tf.cast(x, tf.float32)\n",
    "            x = preproc_layer(x, training=False)\n",
    "            return x, y\n",
    "    else:\n",
    "        MEAN = tf.constant([0.485, 0.456, 0.406], dtype=tf.float32)\n",
    "        STD  = tf.constant([0.229, 0.224, 0.225], dtype=tf.float32)\n",
    "        def _map(x, y):\n",
    "            x = tf.cast(x, tf.float32) / 255.0\n",
    "            x = (x - MEAN) / STD\n",
    "            return x, y\n",
    "\n",
    "    train_ds = train_ds.map(_map, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    val_ds   = val_ds.map(_map,   num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    test_ds  = test_ds.map(_map,  num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds, class_names, num_classes\n",
    "\n",
    "train_ds, val_ds, test_ds, class_names, num_classes = build_datasets(\n",
    "    args.data_dir, args.img_size, args.batch_size, args.val_split, args.seed,\n",
    "    preproc_layer=preproc_layer\n",
    ")\n",
    "print(f\"Classes ({num_classes}):\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714237dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, out_png):\n",
    "    hist = history.history\n",
    "    xx = np.arange(1, len(hist[\"loss\"]) + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 2.25))\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    ax = axs[0]; ax.grid(True); ax.set_ylabel(\"loss\")\n",
    "    ax.plot(xx, hist[\"loss\"],     \"b-\", label=\"loss\")\n",
    "    ax.plot(xx, hist[\"val_loss\"], \"r-\", label=\"val_loss\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    ax = axs[1]; ax.grid(True); ax.set_ylabel(\"accuracy\")\n",
    "    ax.plot(xx, hist[\"accuracy\"],     \"b-\", label=\"accuracy\")\n",
    "    ax.plot(xx, hist[\"val_accuracy\"], \"r-\", label=\"val_accuracy\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    for ax in axs: ax.set_xlabel(\"epoch\")\n",
    "    plt.savefig(out_png, bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, out_png, normalize=True):\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "    plt.figure(figsize=(5.2, 4.5))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(\"Confusion matrix\" + (\" (normalized)\" if normalize else \"\"))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            val = format(cm[i, j], fmt)\n",
    "            plt.text(j, i, val,\n",
    "                     ha=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                     fontsize=7)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def merge_histories(H_list):\n",
    "    merged = {}\n",
    "    for H in H_list:\n",
    "        for k, v in H.history.items():\n",
    "            merged.setdefault(k, [])\n",
    "            merged[k].extend(v)\n",
    "    class _Hist:\n",
    "        def __init__(self, hist):\n",
    "            self.history = hist\n",
    "    return _Hist(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42076d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = keras_hub.models.ImageClassifier.from_preset(\n",
    "    args.preset,\n",
    "    num_classes=num_classes,\n",
    "    activation=\"softmax\",\n",
    "    dropout=0.5,\n",
    ")\n",
    "\n",
    "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "top5_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top5\")\n",
    "\n",
    "reduce_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\", factor=0.4, patience=6, verbose=1\n",
    ")\n",
    "early_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=12, restore_best_weights=True, verbose=1\n",
    ")\n",
    "csv_cb = tf.keras.callbacks.CSVLogger(\n",
    "    os.path.join(args.results_dir, f\"history{tag}.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_epochs = max(1, min(args.warmup_epochs, args.epochs))\n",
    "print(f\"Warmup epochs (frozen backbone): {warmup_epochs}\")\n",
    "\n",
    "M.backbone.trainable = False\n",
    "optimizer_warmup = tf.keras.optimizers.Adam(learning_rate=args.lr_warmup)\n",
    "M.compile(\n",
    "    optimizer=optimizer_warmup,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[acc_metric, top5_metric],\n",
    ")\n",
    "H1 = M.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=warmup_epochs,\n",
    "    callbacks=[csv_cb],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"Fine-tune epochs (unfrozen backbone): {args.epochs - warmup_epochs}\")\n",
    "M.backbone.trainable = True\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr_finetune)\n",
    "M.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[acc_metric, top5_metric],\n",
    ")\n",
    "H2 = M.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch=warmup_epochs,\n",
    "    epochs=args.epochs,\n",
    "    callbacks=[reduce_cb, early_cb, csv_cb],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "H = merge_histories([H1, H2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = M.evaluate(train_ds, return_dict=True, verbose=0)\n",
    "test_metrics  = M.evaluate(test_ds,  return_dict=True, verbose=0)\n",
    "\n",
    "acc_train = float(train_metrics[\"accuracy\"])\n",
    "acc_test  = float(test_metrics[\"accuracy\"])\n",
    "top5_test = test_metrics.get(\"top5\")\n",
    "\n",
    "print(f\"Train accuracy : {acc_train:.2%}\")\n",
    "print(f\"Test accuracy  : {acc_test:.2%}\")\n",
    "if top5_test is not None:\n",
    "    print(f\"Test top-5     : {top5_test:.2%}\")\n",
    "\n",
    "out_png = os.path.join(args.results_dir, f\"history{tag}.png\")\n",
    "plot_history(H, out_png)\n",
    "print(f\"Saved: {out_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True labels\n",
    "y_true = []\n",
    "for _, y in test_ds:\n",
    "    y_true.append(y.numpy())\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "# Predictions\n",
    "y_pred = np.argmax(M.predict(test_ds, verbose=0), axis=1)\n",
    "\n",
    "# Confusion matrix plot\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "cm_png = os.path.join(args.results_dir, f\"confusion_matrix{tag}.png\")\n",
    "plot_confusion_matrix(cm, class_names, cm_png, normalize=True)\n",
    "print(f\"Saved: {cm_png}\")\n",
    "\n",
    "# Per class accuracy\n",
    "per_class_total = cm.sum(axis=1)\n",
    "per_class_correct = np.diag(cm)\n",
    "per_class_acc = np.divide(\n",
    "    per_class_correct,\n",
    "    np.maximum(per_class_total, 1),\n",
    "    out=np.zeros_like(per_class_correct, dtype=float),\n",
    "    where=per_class_total != 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=3\n",
    ")\n",
    "rep_path = os.path.join(args.results_dir, f\"classification_report{tag}.txt\")\n",
    "with open(rep_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report + \"\\n\")\n",
    "    f.write(f\"\\nTrain accuracy: {acc_train:.4f}\\n\")\n",
    "    f.write(f\"Test accuracy : {acc_test:.4f}\\n\")\n",
    "    if top5_test is not None:\n",
    "        f.write(f\"Test top5     : {top5_test:.4f}\\n\")\n",
    "\n",
    "    f.write(\"\\nPer-class accuracy:\\n\")\n",
    "    for cname, acc, tot in zip(class_names, per_class_acc, per_class_total):\n",
    "        f.write(f\"  {cname:>20s}: {acc*100:6.2f}%  (n={int(tot)})\\n\")\n",
    "\n",
    "    meta = {\n",
    "        \"preset\": args.preset,\n",
    "        \"epochs\": int(args.epochs),\n",
    "        \"warmup_epochs\": int(warmup_epochs),\n",
    "        \"batch_size\": int(args.batch_size),\n",
    "        \"lr_warmup\": float(args.lr_warmup),\n",
    "        \"lr_finetune\": float(args.lr_finetune),\n",
    "        \"img_size\": list(args.img_size),\n",
    "        \"seed\": int(args.seed),\n",
    "        \"used_preset_preprocessor\": bool(preproc_layer is not None),\n",
    "    }\n",
    "    f.write(\"\\nMeta:\\n\")\n",
    "    f.write(json.dumps(meta, indent=2))\n",
    "print(f\"Saved: {rep_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
