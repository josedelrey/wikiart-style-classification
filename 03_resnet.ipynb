{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_hub\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    data_dir=\"data/artbench-10\",\n",
    "    img_size=(224, 224),\n",
    "    batch_size=128,\n",
    "    val_split=0.2,\n",
    "    seed=42,\n",
    "    epochs=200,\n",
    "    lr_warmup=5e-4,\n",
    "    lr_finetune=3e-5,\n",
    "    preset=\"resnet_vd_200_imagenet\",\n",
    "    results_dir=\"results\",\n",
    "    warmup_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7058ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm_id = os.environ.get(\"SLURM_JOB_ID\", \"\")\n",
    "tag = f\"_{slurm_id}\" if slurm_id else \"\"\n",
    "\n",
    "os.makedirs(args.results_dir, exist_ok=True)\n",
    "\n",
    "# Seeds\n",
    "tf.keras.utils.set_random_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = history.history\n",
    "    xx = np.arange(1, len(hist[\"loss\"]) + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    ax = axs[0]; ax.grid(True); ax.set_ylabel(\"loss\")\n",
    "    ax.plot(xx, hist[\"loss\"], \"b-\", label=\"loss\")\n",
    "    ax.plot(xx, hist[\"val_loss\"], \"r-\", label=\"val_loss\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    ax = axs[1]; ax.grid(True); ax.set_ylabel(\"accuracy\")\n",
    "    ax.plot(xx, hist[\"accuracy\"], \"b-\", label=\"accuracy\")\n",
    "    ax.plot(xx, hist[\"val_accuracy\"], \"r-\", label=\"val_accuracy\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=True):\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "    plt.figure(figsize=(5.5, 4.5))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=\"viridis\")\n",
    "    plt.title(\"Confusion matrix\" + (\" (normalized)\" if normalize else \"\"))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            val = format(cm[i, j], fmt)\n",
    "            plt.text(j, i, val,\n",
    "                     ha=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                     fontsize=7)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def merge_histories(H_list):\n",
    "    merged = {}\n",
    "    for H in H_list:\n",
    "        for k, v in H.history.items():\n",
    "            merged.setdefault(k, [])\n",
    "            merged[k].extend(v)\n",
    "    class _Hist:\n",
    "        def __init__(self, hist):\n",
    "            self.history = hist\n",
    "    return _Hist(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572caca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(data_dir, img_size, batch_size, val_split, seed):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, \"train\"),\n",
    "        validation_split=val_split,\n",
    "        subset=\"training\",\n",
    "        seed=seed,\n",
    "        image_size=tuple(img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"int\",\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, \"train\"),\n",
    "        validation_split=val_split,\n",
    "        subset=\"validation\",\n",
    "        seed=seed,\n",
    "        image_size=tuple(img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"int\",\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, \"test\"),\n",
    "        image_size=tuple(img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode=\"int\",\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "    val_ds   = val_ds.prefetch(AUTOTUNE)\n",
    "    test_ds  = test_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds, class_names, num_classes\n",
    "\n",
    "train_ds, val_ds, test_ds, class_names, num_classes = build_datasets(\n",
    "    args.data_dir, args.img_size, args.batch_size, args.val_split, args.seed\n",
    ")\n",
    "print(f\"Classes ({num_classes}):\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b87324",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = keras_hub.models.ImageClassifier.from_preset(\n",
    "    args.preset,\n",
    "    num_classes=num_classes,\n",
    "    activation=\"softmax\",\n",
    "    dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "top5_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top5\")\n",
    "\n",
    "reduce_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\", factor=0.4, patience=6, verbose=0\n",
    ")\n",
    "early_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=12, restore_best_weights=True, verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_epochs = max(1, min(args.warmup_epochs, args.epochs))\n",
    "print(f\"Warmup epochs (frozen backbone): {warmup_epochs}\")\n",
    "\n",
    "M.backbone.trainable = False\n",
    "optimizer_warmup = tf.keras.optimizers.Adam(learning_rate=args.lr_warmup)\n",
    "M.compile(\n",
    "    optimizer=optimizer_warmup,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[acc_metric, top5_metric],\n",
    ")\n",
    "H1 = M.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=warmup_epochs,\n",
    "    callbacks=[csv_cb],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fine-tune epochs (unfrozen backbone): {args.epochs - warmup_epochs}\")\n",
    "M.backbone.trainable = True\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr_finetune)\n",
    "M.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[acc_metric, top5_metric],\n",
    ")\n",
    "H2 = M.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    initial_epoch=warmup_epochs,\n",
    "    epochs=args.epochs,\n",
    "    callbacks=[reduce_cb, early_cb, csv_cb],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a72d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = merge_histories([H1, H2])\n",
    "train_metrics = M.evaluate(train_ds, return_dict=True, verbose=0)\n",
    "test_metrics  = M.evaluate(test_ds,  return_dict=True, verbose=0)\n",
    "\n",
    "acc_train = float(train_metrics[\"accuracy\"])\n",
    "acc_test  = float(test_metrics[\"accuracy\"])\n",
    "top5_test = test_metrics.get(\"top5\")\n",
    "\n",
    "print(f\"Train accuracy : {acc_train:.2%}\")\n",
    "print(f\"Test accuracy  : {acc_test:.2%}\")\n",
    "print(f\"Test top-5     : {top5_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63fdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True labels\n",
    "y_true = []\n",
    "for _, y in test_ds:\n",
    "    y_true.append(y.numpy())\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "# Predictions\n",
    "y_pred = np.argmax(M.predict(test_ds, verbose=0), axis=1)\n",
    "\n",
    "# Confusion matrix plot\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "plot_confusion_matrix(cm, class_names, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=3\n",
    ")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
